\documentclass[11pt]{article}
\usepackage{amsmath, amssymb,amsthm,enumerate}
\usepackage{hyperref}
\usepackage{cite}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 } 

\title{Probability Theory Homework I}
\author{Bohao Tang}
\date{\today} 

\begin{document}
\maketitle

\begin{enumerate}[1]
	\item
	\begin{enumerate}[(i)]
		\item 
		\begin{proof}
		We have $a_1 > 0$ and since $a_n \to 0$, there exists $N$ such that for every $n > N$,
		$a_n < a_1$. Therefore $\max_{1 \le n} \{a_n\}$ is $\max_{1 \le n \le N} \{a_n\}$, and
		then the max exits since $N < \infty$ 
		\end{proof}
		\item
		\begin{proof}
		Suppose $A$ is uncountable, then $A \setminus \{0\}$ is also uncountable. Since
		$A \setminus \{0\} = \cup_{n=1}^{\infty} A_n$ where $A_n = \{a \in A: a \ge 1/n \}$,
		then there must exits a $N$ such that $A_N$ is uncountable, and therefore $N+1$
		elements $\{a_1,\cdots,a_{N+1}\}$ in $A_N \subset A$ such that $\forall i: \  a_i \ge 1/N$.
		We'll have $\sum_{i=1}^{N+1} a_i \ge \frac{N+1}{N} > 1$. A contradiction, so $A$
		must be countable.	
		\end{proof}
	\end{enumerate}
	\item
	\begin{enumerate}[(i)]
		\item 
		\begin{proof}
			Suppose in $(M,d_1)$: $x_n \to x$ and in $(M,d_2)$: $x_n \to y$ and $x \ne y$,
			which infers $d_2(x,y) > 0$.
			Then we consider an array $y_n$, where $y_{2k+1} = x$ and $y_{2k} = x_k$.
			It's easy to see that $y_n$ has limit $x$ in $(M,d_1)$, so according to the assumption
			in problem, $y_n$ must tend to some $z \in M$.
			Therefore $d_2(y_{2k+1}, y_{2k}) \le d_2(y_{2k+1}, z) + d_2(z, y_{2k})$ tends to $0$.
			However when $k$ is large enough:
			$$d_2(y_{2k+1}, y_{2k}) \ge d_2(y_{2k+1}, y) - d_2(y, y_{2k}) = d_2(x,y) - d_2(y,x_k) > d_2(x,y)/2 > 0$$
			A contradiction shows up, therefore $x = y$.
		\end{proof}
		\item
		\begin{proof}
			For every sequence $(x_n, y_n)$ in the set, if $(x_n, y_n) \to (x_0, y_0)$. Then since
			function $y - x^2$ is continuous with $(x,y)$, we have $\lim (y_n - x_n^2) = (y_0 - x_0^2)$, and since $(x_n,y_n) \in \{(x,y): y \ge x^2 \}$, we have $\lim (y_n - x_n^2) \ge 0$ and therefore $y_0 \ge x_0^2$ and $(x_0,y_0) \in \{(x,y): y \ge x^2 \}$, which means the set is closed.
		\end{proof}
		\item
		\begin{enumerate}[(a)]
			\item $(0,1+\frac{1}{n})$ are open but $\cap_{n=1}^\infty (0, 1 + \frac{1}{n}) = (0 , 1]$ is not open.
			\item $\{(x,x^2): x \in [0,1]\} \cap \{(x,x): x \in [0,1]\} = \{(0,0),(1,1)\}$ is not connected. 
		\end{enumerate}
	\end{enumerate}
	\item
	\begin{enumerate}[(i)]
		\item 
		\begin{proof}
			Suppose $M$ is infinite, since $M$ is compact, an infinite subarray of $M$ must have an accumulation point, which means we can find an array $\{x_n\}$ of distinct elements in $M$
			such that $x_n \to x$ and $x \notin \{x_n\}$. Therefore $\{x_n\}$ is a subset of $M$, hence compact, but not closed. However, since $M$ is a metric space, hence $T_2$ space, every compact set in $M$ must be closed \cite{topology}. A contradiction, which means $M$ is finite
		\end{proof}
		\item 
		\begin{proof}
			For every open cover $\{O_\alpha\}$ of $f(K)$, $\{f^{-1}(O_\alpha)\}$ will be an open
			cover of $K$. Since $K$ is compact, there exists an finite subcover $\{f^{-1}(O_{\alpha_i})\}_1^N$. Then:
			$$f(K) \subset f\left( \cup_1^N f^{-1}(O_{\alpha_i}) \right) = \cup_1^N f(f^{-1}(O_{\alpha_i})) = \cup_1^N O_{\alpha_i}$$
			So $\{O_{\alpha_i}\}_1^N$ is an finite open subcover of $f(K)$. Therefore, $f(K)$ is compact.
		\end{proof}
	\end{enumerate}
	\item 
	\begin{enumerate}[(i)]
		\item
		\begin{proof}
			By using derivative, $f_n(x)$ is increase in $[0, \frac{1}{\sqrt{3} n}]$ and decrease in
			$[\frac{1}{\sqrt{3} n}, 1]$. So we have:
			$$\sup_{x\in[0,1]} |f_n(x) - 0| = f_n(\frac{1}{\sqrt{3} n}) > \frac{1}{2} > 0$$
			therefore $f_n$ don't uniformly convergent to $0$ in $[0,1]$. But in $[\delta,1]$, when $n$ is large enough such that $\frac{1}{\sqrt{3} n} < \delta$, we have:
			$$\sup_{x\in[\delta,1]} |f_n(x) - 0| = f_n(\delta) = \frac{\sqrt{n \delta}}{n^2 \delta^2 + 1} \to 0$$ 
			therefore, $f_n$ uniformly convergent to $0$ in every $[\delta, 1]$ where $\delta > 0$.
		\end{proof}
		\item
		$|(1+n^2)^{-2} \sin(n x)|, |n (1+n^2)^{-2} \cos(n x)|, |(-1)^n n^2 (1+n^2)^{-2} \sin(n x)|$
		are all less than $\frac{1}{1 + n^2}$, where $\sum_1^\infty \frac{1}{1 + n^2} < \infty$. Therefore (a), (b), (c) are all uniformly convergent to some function \cite{wei}.
		
		Since $(\frac{\sin(n x)}{(1+n^2)^2})' = n (1+n^2)^{-2} \cos(n x)$, which is continuous and (a) and (b)
		convergent uniformly, we have \cite{deriv}:
		$$\left( \sum_{n=1}^{\infty} (1+n^2)^{-2} \sin(n x) \right)' = \sum_{n=1}^{\infty} n (1+n^2)^{-2} \cos(n x)$$
		And in the same way, we can prove that:
		$$\left( \sum_{n=1}^{\infty} n (1+n^2)^{-2} \cos(n x) \right)' = \sum_{n=1}^{\infty} (-1) n^2 (1+n^2)^{-2} \sin(n x)$$
		So, $f'' = \sum_{n=1}^{\infty} (-1) n^2 (1+n^2)^{-2} \sin(n x)$ exists and it's continuous since uniform convergence and the continuousness of $\sin (nx)$ \cite{contin}. 
	\end{enumerate}
	\item
	\begin{enumerate}[(i)]
		\item 
		Since every nonempty interval in $\mathbb{R}$ contains rational and irrational number. Therefore every upper sum is $1$ and every lower sum is $0$, hence $f$ is not Riemann integrable.
		\item
		\begin{proof}
			In this situation we have that $f$ is uniformly continuous \cite{uniform} in $[a,b]$, which means
			$\forall \epsilon > 0, \exists \delta > 0$ $\forall |x - y| < \delta$
			we have $|f(x) - f(y)| < \epsilon$. 
			
			For this (but arbitary) $\epsilon$ and $\delta$, $\forall$ partition
			$0 = x_0 < x_1 < \cdots < x_N = 1$  with $\max_{0 \le i \le N-1} (x_{i+1} - x_i) < \epsilon$.
			Denote $U$, $L$ be the upper sum and the lower sum, then we have:
			$$|U - L| \le \epsilon \cdot \sum_{i=0}^{N-1} (x_{i+1} - x_i) = \epsilon$$
			which means $|U - L| \to 0$ when $\max_{0 \le i \le N-1} (x_{i+1} - x_i) \to 0$. 
			Therefore $f$ is Riemann integrable. 	
		\end{proof} 
		\item 
		\begin{proof}
			We have $0 \le f_n(x) < 1, \forall x \in [0,1]$ and $\forall \delta > 0$, $f_n$
			uniformly convergent to $0$, hence $\lim \int_\delta^1 f_n(x) d x = 0, \forall \delta > 0$ \cite{integ}.
			Therefore we have:
			$$\int_0^1 f_n(x) d x = \int_0^\delta f_n(x) d x + \int_\delta^1 f_n(x) d x < \delta + \int_\delta^1 f_n(x) d x$$
			then:
			$$\varlimsup_{n\to\infty} \int_0^1 f_n(x) d x < \delta, \hspace{0.5cm} \forall \delta > 0$$
			which means $\varlimsup \int_0^1 f_n(x) d x = 0$, together with $f_n \ge 0$,
			we have $\lim \int_0^1 f_n(x) d x = 0$.
		\end{proof} 
	\end{enumerate}
\end{enumerate}

\section*{\normalsize{Bonus:}}

Suppose the strategy is to switch the number with probability $p(x)$ when we get $x$,
then calculate the probability that we end with a larger number if two numbers are $x$ and $2x$.
It's:
$$\textbf{P}(\text{end with larger number}) = \frac{1}{2} p(x) + \frac{1}{2} \left( 1 - p(2x) \right) = \frac{1}{2} + \frac{p(x) - p(2x)}{2}$$
So we only need $p(x) > p(2x)$, for example we can switch the number with probability $\frac{1}{1+x}$ when we get $x$,
and then we will have more chance than $1/2$ to get the biggest number for every $x$.

\begin{thebibliography}{1}
	\bibitem{topology} \textbf{Theorem 26.3. "Every compact subspace of a Hausdorff space is closed"}. Munkres, James R. \textit{Topology}. Prentice Hall, 2000.
	\bibitem{uniform} \textbf{Theorem 4.19. "Let $f$ be a continuous mapping of a compact metric space $X$ into a metric space $Y$. Then $f$ is uniformly continuous on $X$ "}. Rudin, Walter. \textit{Principles of mathematical analysis}. Vol. 3. New York: McGraw-hill, 1964.	
	\bibitem{wei} \textbf{Theorem 7.10. "$\cdots$ suppose $|f_n(x)| \le M_n \cdots$ Then $\sum f_n$ converges uniformly $\cdots$ if $\sum M_n$ converges "}. Rudin, Walter. \textit{Principles of mathematical analysis}. Vol. 3. New York: McGraw-hill, 1964.
	\bibitem{contin} \textbf{Theorem 7.12. "If $\{f_n\}$ is a sequence of continuous functions on $E$, and if $f_n \to f$ uniformly on $E$, then f is continuous on E"}. Rudin, Walter. \textit{Principles of mathematical analysis}. Vol. 3. New York: McGraw-hill, 1964.	
	\bibitem{integ} \textbf{Theorem 7.16. "$\cdots f_n \to f$ uniformly on $[a,b]$. Then $\cdots$ and $\int_a^b f d \alpha = \lim_{n\to\infty} \int_a^b f_n d \alpha$ "}. Rudin, Walter. \textit{Principles of mathematical analysis}. Vol. 3. New York: McGraw-hill, 1964.		
	\bibitem{deriv} \textbf{Theorem 7.17. "Suppose $\{f_n\}$ is a sequence of functions, differentiable on $[a,b]$ and such that $\{f_n(x_0)\}$ converges for some point $x_0$ on $[a,b]$. If $\{f_n'\}$ converges uniformly on $[a,b]$, then $\{f_n\}$ converges uniformly on $[a,b]$, to a function $f$, and $f'(x) = \lim_{n\to\infty} f_n'(x)$"}. Rudin, Walter. \textit{Principles of mathematical analysis}. Vol. 3. New York: McGraw-hill, 1964.	
\end{thebibliography}

\end{document}

